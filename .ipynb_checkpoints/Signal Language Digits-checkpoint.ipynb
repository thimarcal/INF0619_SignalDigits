{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final\n",
    "Neste trabalho, vamos buscar o reconhecimento dos dígitos da Linguagem de Sinais. Para tal, vamos nos utilizar de Modelos conhecidos de Deep Learning e também nos aventurar na criação de próprios.\n",
    "\n",
    "------\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "O dataset é composto por 10 classes (dígitos de 0 a 9) com aproximadamente 205 imagens por classe. \n",
    "O conjunto foi dividido em 60% para treinamento, 15% para validação e 20% para teste.\n",
    "As imagens estão divididas em blocos por classe.\n",
    "\n",
    "** IMPORTANTE NÃO ALTERAR O NOME/LOCAL DAS IMAGENS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDir = \"./Dataset\"\n",
    "nbClasses = 10\n",
    "input_shape = (100,100,3)\n",
    "\n",
    "train_files = {}\n",
    "val_files = {}\n",
    "test_files = {}\n",
    "\n",
    "def splitData():\n",
    "    # Initially Split Data between Train / Validation and Test\n",
    "    # This data will be used during all process, and epochs will shuffle only train data\n",
    "    for i in range(nbClasses):\n",
    "        filenames = os.listdir(os.path.join(datasetDir, str(i)))\n",
    "        shuffledFiles = sample(filenames, len(filenames))\n",
    "\n",
    "        # 60% for Train\n",
    "        # 15% for Validation\n",
    "        # 25% for Test\n",
    "        for index, file in enumerate(shuffledFiles):\n",
    "            file = os.path.join(datasetDir, str(i), file)\n",
    "            if index < len(filenames)*0.6:\n",
    "                train_files[file] = i\n",
    "            elif index < len(filenames)*0.75:\n",
    "                val_files[file] = i\n",
    "            else:\n",
    "                test_files[file] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the images from imgList\n",
    "def plotImages(imgListDict):\n",
    "    for imgPath in imgListDict.keys():\n",
    "        #imgPath = os.path.join(datasetDir, str(imgListDict.get(key)), key)\n",
    "        plotImage(imgPath)\n",
    "\n",
    "#plot the images from imgList\n",
    "def plotImagesFromBatch(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "\n",
    "def plotImage(imagePath):\n",
    "    print(imagePath)\n",
    "    img1 = img_to_array(load_img(imagePath, target_size=input_shape))\n",
    "    img1 = img1.astype('float32')\n",
    "    img1 /= 255.0\n",
    "    \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img1*255.0), interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "splitData()\n",
    "# Se quiser visualizar algum bloco de imagens, descomentar as linhas abaixo\n",
    "# plotImages(val_files)\n",
    "# plotImages(train_files)\n",
    "# plotImages(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images in Train set:  1242\n",
      "# images in Val set:  309\n",
      "# images in Test set:  511\n"
     ]
    }
   ],
   "source": [
    "def getDatasetSize(split='train'):\n",
    "    if split not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(split + \" not recognized. Did you mean 'train', 'val' or 'test'?\")\n",
    "    \n",
    "    if split == 'train':\n",
    "        return len(train_files)\n",
    "    elif split == 'val':\n",
    "        return len(val_files)\n",
    "    else:\n",
    "        return len(test_files)\n",
    "\n",
    "def getLabelFromImgName(imgPath, split):\n",
    "    if split == 'train':\n",
    "        return train_files.get(imgPath)\n",
    "    elif split == 'val':\n",
    "        return val_files.get(imgPath)\n",
    "    else:\n",
    "        return test_files.get(imgPath)\n",
    "    \n",
    "#Read our dataset in batches\n",
    "def loadDatasetInBatches(split=\"train\", batch_size=32):\n",
    "    if split not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(split + \" not recognized. Did you mean 'train', 'val' or 'test'?\")\n",
    "    \n",
    "    if split == 'train':\n",
    "        fileNames = train_files\n",
    "    elif split == 'val':\n",
    "        fileNames = val_files\n",
    "    else:\n",
    "        fileNames = test_files\n",
    "    \n",
    "    while True:\n",
    "        imagePaths = sample(fileNames.keys(), len(fileNames)) #shuffle images in each epoch\n",
    "        \n",
    "        batch, labelList = [], []\n",
    "        nInBatch = 0\n",
    "        \n",
    "        #loop of one epoch\n",
    "        for idx in list(range(len(imagePaths))):\n",
    "                        img = img_to_array(load_img(imagePaths[idx], target_size=input_shape))\n",
    "                        img = img.astype('float32')\n",
    "                        img /= 255.0\n",
    "                    \n",
    "                        label = np_utils.to_categorical(getLabelFromImgName(imagePaths[idx], split), nbClasses)\n",
    "                        \n",
    "                        ######### If you want to run with Data Augmentation, just uncomment here\n",
    "                        ##### you can add more transformations (see https://keras.io/preprocessing/image/)\n",
    "                        ### We apply a random transformation and add this image (instead of the original)\n",
    "                        ### to the batch...\n",
    "                        \n",
    "                        #dataAugmentator = ImageDataGenerator(horizontal_flip = True)\n",
    "                        #img = dataAugmentator.random_transform(img)\n",
    "                        \n",
    "                        \n",
    "                        batch.append(img)\n",
    "                        labelList.append(label)\n",
    "                        nInBatch += 1\n",
    "                        \n",
    "                        #if we already have one batch, yields it\n",
    "                        if nInBatch >= batch_size:\n",
    "                            yield np.array(batch), np.array(labelList)\n",
    "                            batch, labelList = [], []\n",
    "                            nInBatch = 0\n",
    "\n",
    "        #yield the remaining of the batch\n",
    "        if nInBatch > 0:\n",
    "            yield np.array(batch), np.array(labelList)\n",
    "\n",
    "    \n",
    "trainSetSize = getDatasetSize(\"train\")\n",
    "valSetSize = getDatasetSize(\"val\")\n",
    "testSetSize = getDatasetSize(\"test\")\n",
    "\n",
    "print(\"# images in Train set: \", trainSetSize)\n",
    "print(\"# images in Val set: \", valSetSize)\n",
    "print(\"# images in Test set: \", testSetSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo base da SqueezeNet\n",
    "As funções abaixo criam o modelo da SqueezeNet e carregam os seus pesos treinados no ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 100, 100, 3) (5, 10)\n"
     ]
    }
   ],
   "source": [
    "for batch, labels in loadDatasetInBatches(split='train', batch_size=5):\n",
    "    print(batch.shape, labels.shape)\n",
    "    #plotImagesFromBatch(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o load do dados é feito...  \n",
    "O método que iremos utilizar para ler os dados é o `loadDatasetInBatches(split='train', batch_size=32)`. Ele é um generator (semelhante ao método que fazia a aumentação de dados na Aula 03), ou seja, ele gera um fluxo de batches e labels a partir do nosso dataset.\n",
    "\n",
    "**Argumentos**:\n",
    "- (string) **split**: pode ser `'train'`, `'val'` ou `'test'`. Se refere a qual conjunto de dados que iremos ler (treino, validação ou teste);\n",
    "- (int) **batch_size**: quantas imagens por batch;\n",
    "\n",
    "**Retorno**: \n",
    "- **batch**: retorna um array do numpy com as imagens carregadas e pre-processadas. **batch** tem dimensões (batch_size, 227, 227, 3), pois as imagens tem tamanho 227x227 e tem 3 canais (RGB);\n",
    "- **labels**: retorna um array do numpy com as labels já transformadas em one_hot_encode (array de 83 dimensões, com 1 na posição do índice da classe e 0 nas outras posições). **batch** tem dimensões (batch_size, 83);\n",
    "    \n",
    "Utilizando o argumento `split`, o método lê os nomes das imagens do diretório correto e as embaralha (para garantir que a cada época os batches sejam diferentes). Para cada época (um loop do `for` interno), o método irá carregar uma imagem por vez e irá gerar a sua label (obtendo a classe pelo próprio nome da imagem). Esta imagem/label será colocada em listas **batch/labelList**.\n",
    "\n",
    "Quando estas listas estiverem com **batch_size** elementos, teremos gerado um batch. O método dá um yield nessas duas e recomeça a construção de um novo batch. Quando o `for` terminar, iremos ter completado uma época. O `while True` apenas garante uma nova época seja iniciada. Quem controlará o fim do `while` vai ser o método que fará o fit, portanto não precisamos nos preocupar com isso.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "** -----> A tarefa começa aqui !!! Vocês não precisam modificar nada dos códigos acima!** \n",
    "\n",
    "# Definição do modelo [0.25 pts]\n",
    "\n",
    "- Instancie o modelo base da SqueezeNet;\n",
    "- Escolha qual camada da rede que você utilizará como ponto de partida (..., fire8, fire9, drop9);\n",
    "- Escolha quais camadas terão os pesos atualizados e quais serão congeladas;\n",
    "- Adicione as camadas adicionais no topo da rede. Vocês estão livres em relação à quantidade e tipo de camadas após a SqueezeNet.\n",
    "    - Lembrem-se que ao final da rede, precisamos de camadas de classificação:\n",
    "        - Conv2D + GlobalAveragePooling + SoftMax (aula 05)\n",
    "        - Flatten + Dense + SoftMax (aulas anteriores)\n",
    "    - Se acharem necessário, podem também adicionar outras camadas (Dropout, Conv2D, módulos Fire);\n",
    "    \n",
    "    \n",
    "**Não se esqueçam de:**\n",
    "- Definir novas camadas da mesma forma que fizemos na Aula 05 (utilizando o x = ...(x))\n",
    "- Ao final da célula, definir o modelo novo com o input da squeeze base e o output da última camada adicionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo base da squeezeNet \n",
    "squeezeNetModel = SqueezeNet((100,100,3))\n",
    "\n",
    "# Escolher a camada que será o ponto de partida \n",
    "x = squeezeNetModel.get_layer(name=\"fire9/concat\").output\n",
    "\n",
    "#print([layer.name for layer in squeezeNetModel.layers])\n",
    "#print(\"\\n\\nFreeze layers up until \", squeezeNetModel.layers[-20].name)\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    layer.trainable = True#        layer.trainable = False\n",
    "\n",
    "x = Convolution2D(1024, (1, 1), padding='valid', name='conv10_new')(x)\n",
    "x = Activation('relu', name='relu_conv10_new')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Convolution2D(nbClasses, (1, 1), padding='valid', name='conv11_new')(x)\n",
    "x = Activation('relu', name='relu_conv11_new')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='loss_new')(x)\n",
    "\n",
    "\n",
    "# Não se esqueça de definir o nome modelo, onde baseSqueezeNetModel \n",
    "# é o modelo base da Squeeze que vc definiu ali em cima\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento [0.25 pts]\n",
    "\n",
    "- Compile o seu modelo, definindo qual a loss e otimizador que serão utilizados;\n",
    "- Defina também número de batches e número de épocas;\n",
    "- Treine para obter a maior acurácia que você conseguirem;\n",
    "\n",
    "\n",
    "No treinamento iremos utilizar o `fit_generator` (mesmo utilizado no Aula03 com Data Augmentation). Ele recebe um generator (que será fornecido pelo `loadDatasetInBatches`). Como o generator retorna um fluxo de batches/labels, o `fit_generator` não tem informação sobre o tamanho dataset. Por isso, precisamos informar o número de épocas (parâmetro `epochs`) e também quantos batches compõe uma época (parâmetro `steps_per_epoch`). Ao total, teremos 2 generators, um para o conjunto de treino e outro para o conjunto de teste.\n",
    "\n",
    "Para mais informações sobre o fit_generator e seus parâmetros, [acesse a documentação do Keras](https://keras.io/models/sequential/#fit_generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "#Compile o modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True), metrics=['accuracy'])\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./logs_squeeze8\")\n",
    "tbEarly = callbacks.EarlyStopping(monitor='val_acc',min_delta=0,patience=10,verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 6s 150ms/step - loss: 2.4081 - acc: 0.1151 - val_loss: 2.2340 - val_acc: 0.2674\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 9s 246ms/step - loss: 2.2287 - acc: 0.2309 - val_loss: 2.1212 - val_acc: 0.3466\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 2.0928 - acc: 0.2824 - val_loss: 1.9416 - val_acc: 0.4477\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 13s 330ms/step - loss: 1.8763 - acc: 0.3979 - val_loss: 1.6823 - val_acc: 0.4946\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 6s 147ms/step - loss: 1.5614 - acc: 0.4899 - val_loss: 1.2644 - val_acc: 0.6534\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 8s 212ms/step - loss: 1.2128 - acc: 0.6162 - val_loss: 0.8850 - val_acc: 0.8014\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.8956 - acc: 0.7311 - val_loss: 0.6303 - val_acc: 0.8195\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 4s 99ms/step - loss: 0.6579 - acc: 0.7861 - val_loss: 0.5035 - val_acc: 0.8556\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 0.5058 - acc: 0.8282 - val_loss: 0.3708 - val_acc: 0.9061\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 0.3749 - acc: 0.8917 - val_loss: 0.2826 - val_acc: 0.9278\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.3179 - acc: 0.9039 - val_loss: 0.2549 - val_acc: 0.9271\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.2449 - acc: 0.9252 - val_loss: 0.1933 - val_acc: 0.9422\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.2149 - acc: 0.9427 - val_loss: 0.2095 - val_acc: 0.9242\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 0.1813 - acc: 0.9455 - val_loss: 0.1524 - val_acc: 0.9531\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 7s 186ms/step - loss: 0.1769 - acc: 0.9507 - val_loss: 0.1596 - val_acc: 0.9422\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.1330 - acc: 0.9679 - val_loss: 0.1873 - val_acc: 0.9422\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 0.1412 - acc: 0.9622 - val_loss: 0.1261 - val_acc: 0.9711\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.1097 - acc: 0.9735 - val_loss: 0.1143 - val_acc: 0.9711\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 0.0999 - acc: 0.9710 - val_loss: 0.1202 - val_acc: 0.9639\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 0.0833 - acc: 0.9825 - val_loss: 0.1236 - val_acc: 0.9675\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0922 - acc: 0.9719 - val_loss: 0.1190 - val_acc: 0.9722\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 0.0714 - acc: 0.9825 - val_loss: 0.1190 - val_acc: 0.9675\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0570 - acc: 0.9877 - val_loss: 0.1129 - val_acc: 0.9675 0.0556 - a\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0693 - acc: 0.9852 - val_loss: 0.0619 - val_acc: 0.9747\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 0.0578 - acc: 0.9875 - val_loss: 0.1171 - val_acc: 0.9711\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0690 - acc: 0.9844 - val_loss: 0.1165 - val_acc: 0.9639\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 0.0498 - acc: 0.9885 - val_loss: 0.1202 - val_acc: 0.9783\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 11s 288ms/step - loss: 0.0474 - acc: 0.9885 - val_loss: 0.0735 - val_acc: 0.9747\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0386 - acc: 0.9942 - val_loss: 0.1012 - val_acc: 0.9783\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 0.0416 - acc: 0.9918 - val_loss: 0.1007 - val_acc: 0.9819\n"
     ]
    }
   ],
   "source": [
    "#Definir tamanho do batch e número de épocas\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "#Criação dos generators\n",
    "trainGenerator = loadDatasetInBatches(split='train', batch_size = batch_size)\n",
    "valGenerator = loadDatasetInBatches(split='val', batch_size = batch_size)\n",
    "\n",
    "#Fit nos dados\n",
    "hist = model.fit_generator(trainGenerator, \n",
    "                    steps_per_epoch= int(trainSetSize / batch_size), \n",
    "                    epochs = epochs,\n",
    "                    validation_data = valGenerator,  \n",
    "                    validation_steps = int(valSetSize / batch_size),\n",
    "                    callbacks=[tbCallBack, tbEarly])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste [0.25 pts]\n",
    "O teste será feito da mesma forma, utilizando `loadDatasetInBatches` para o conjunto de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 61ms/step\n",
      "Test Loss --->  0.08768321151534716\n",
      "Test Accuracy --->  0.96875\n"
     ]
    }
   ],
   "source": [
    "#Criação do generator p/ o conjunto de teste\n",
    "testGenerator = loadDatasetInBatches(split='test', batch_size=batch_size)\n",
    "\n",
    "#Teste\n",
    "metrics = model.evaluate_generator(testGenerator, \n",
    "                                   steps=int(testSetSize/batch_size), \n",
    "                                   verbose=1)\n",
    "\n",
    "print(\"Test Loss ---> \", metrics[0])\n",
    "print(\"Test Accuracy ---> \", metrics[1])    #Test is balanced, so Acc is normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões  [0.25 pts]\n",
    "Escrevam um parágrafo com as conclusões que vocês tiraram na tarefa. Comentem as dificuldades encontradas, as tentativas feitas, como foi o seu treinamento, apontando a motivação pelas decisões tomadas. Se o resultado ficou melhor/pior do que o que você esperava, o que você acha que pode ter acontecido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
