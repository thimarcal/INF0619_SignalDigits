{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final\n",
    "Neste trabalho, vamos buscar o reconhecimento dos dígitos da Linguagem de Sinais. Para tal, vamos nos utilizar de Modelos conhecidos de Deep Learning e também nos aventurar na criação de próprios.\n",
    "\n",
    "------\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "\n",
    "import inf619utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "O dataset é composto por 10 classes (dígitos de 0 a 9) com aproximadamente 205 imagens por classe. \n",
    "O conjunto foi dividido em 60% para treinamento, 15% para validação e 20% para teste.\n",
    "As imagens estão divididas em blocos por classe.\n",
    "\n",
    "** IMPORTANTE NÃO ALTERAR O NOME/LOCAL DAS IMAGENS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_file = 'keras_mobilenet.h5'\n",
    "\n",
    "datasetDir = \"./Dataset\"\n",
    "datasetDirSplitted = \"./DatasetSplitted\"\n",
    "nbClasses = 10\n",
    "input_shape = (224,224,3)\n",
    "input_size = (224,224)\n",
    "\n",
    "train_files = {}\n",
    "val_files = {}\n",
    "test_files = {}\n",
    "\n",
    "train_files, val_files, test_files = inf619utils.splitData(datasetDir, nbClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the images from imgList\n",
    "def plotImagesFromBatch(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "\n",
    "\n",
    "# Se quiser visualizar algum bloco de imagens, descomentar as linhas abaixo\n",
    "# inf619utils.plotImages(val_files)\n",
    "# inf619utils.plotImages(train_files)\n",
    "# inf619utils.plotImages(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(input_shape=input_shape, classes=nbClasses, include_top=False)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modificação do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher a camada que será o ponto de partida \n",
    "x = model.output\n",
    "\n",
    "#print([layer.name for layer in squeezeNetModel.layers])\n",
    "#print(\"\\n\\nFreeze layers up until \", squeezeNetModel.layers[-20].name)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True#        layer.trainable = False\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# Não se esqueça de definir o nome modelo, onde baseSqueezeNetModel \n",
    "# é o modelo base da Squeeze que vc definiu ali em cima\n",
    "model = Model(model.inputs, x, name='mobilenet_new_adam')\n",
    "#model2 = Model(squeezeNetModel.inputs, x, name='squeezenet_new_adadelta')\n",
    "#model3 = Model(squeezeNetModel.inputs, x, name='squeezenet_new_sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir tamanho do batch e número de épocas\n",
    "batch_size = 24\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "#Compile o modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./logs_mobilenet\")\n",
    "tbEarly = callbacks.EarlyStopping(monitor='val_acc',min_delta=0,patience=3,verbose=0, mode='auto')\n",
    "tbEarly100 = callbacks.EarlyStopping(monitor='acc', min_delta=0.0001, patience=3, mode='max')\n",
    "tbModelChk = callbacks.ModelCheckpoint('.modelmobilenet_weights.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1242 images belonging to 10 classes.\n",
      "Found 309 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        datasetDirSplitted + '\\\\train',\n",
    "        target_size=input_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        datasetDirSplitted + '\\\\val',\n",
    "        target_size=input_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51/51 [==============================] - 124s 2s/step - loss: 3.0517 - acc: 0.2247 - val_loss: 2.1648 - val_acc: 0.3924\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 113s 2s/step - loss: 1.6997 - acc: 0.4599 - val_loss: 1.5302 - val_acc: 0.5439\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 1.1599 - acc: 0.6100 - val_loss: 0.9839 - val_acc: 0.6632\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.8837 - acc: 0.7072 - val_loss: 0.7540 - val_acc: 0.7404\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.6620 - acc: 0.7767 - val_loss: 0.7736 - val_acc: 0.7614\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.5997 - acc: 0.7922 - val_loss: 0.7237 - val_acc: 0.7719\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.4634 - acc: 0.8331 - val_loss: 0.4851 - val_acc: 0.8351\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.3660 - acc: 0.8668 - val_loss: 0.5003 - val_acc: 0.8526\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 111s 2s/step - loss: 0.3455 - acc: 0.8810 - val_loss: 0.4944 - val_acc: 0.8596\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.2991 - acc: 0.8870 - val_loss: 0.4473 - val_acc: 0.8877\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.2544 - acc: 0.9039 - val_loss: 0.4092 - val_acc: 0.8877\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.2426 - acc: 0.9172 - val_loss: 0.3645 - val_acc: 0.8982\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.1923 - acc: 0.9363 - val_loss: 0.3589 - val_acc: 0.8947\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.1783 - acc: 0.9431 - val_loss: 0.3820 - val_acc: 0.8958\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.1613 - acc: 0.9510 - val_loss: 0.3238 - val_acc: 0.9088\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.1414 - acc: 0.9534 - val_loss: 0.3229 - val_acc: 0.9298\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 111s 2s/step - loss: 0.1424 - acc: 0.9589 - val_loss: 0.3254 - val_acc: 0.8667\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.1264 - acc: 0.9619 - val_loss: 0.2118 - val_acc: 0.9333\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.1066 - acc: 0.9695 - val_loss: 0.3762 - val_acc: 0.9088\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.1160 - acc: 0.9611 - val_loss: 0.2307 - val_acc: 0.9263\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 112s 2s/step - loss: 0.0978 - acc: 0.9657 - val_loss: 0.3054 - val_acc: 0.9193\n"
     ]
    }
   ],
   "source": [
    "#Fit nos dados\n",
    "#Fit nos dados\n",
    "hist = model.fit_generator(train_generator, \n",
    "                    steps_per_epoch= int(1242/batch_size), \n",
    "                    epochs = epochs,\n",
    "                    validation_data = validation_generator,  \n",
    "                    validation_steps = int(309/batch_size),\n",
    "                    callbacks=[tbCallBack, tbEarly, tbEarly100, tbModelChk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(keras_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do Modelo no Conjunto de Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Best weights saved\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.applications.mobilenet import DepthwiseConv2D, relu6\n",
    "from keras.models import load_model\n",
    "\n",
    "with CustomObjectScope({'relu6': relu6,'DepthwiseConv2D': DepthwiseConv2D}):\n",
    "    model = load_model(keras_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 511 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        datasetDirSplitted + '\\\\test',\n",
    "        target_size=input_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss MobileNet--->  0.26169243418482185\n",
      "Test Accuracy MobileNet--->  0.9138943252031584\n"
     ]
    }
   ],
   "source": [
    "#Criação do generator p/ o conjunto de teste\n",
    "\n",
    "#Teste\n",
    "metrics = model.evaluate_generator(test_generator)\n",
    "\n",
    "print(\"Test Loss MobileNet---> \", metrics[0])\n",
    "print(\"Test Accuracy MobileNet---> \", metrics[1])    #Test is balanced, so Acc is normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar matrix de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator)\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        51\n",
      "           1       0.91      0.96      0.93        51\n",
      "           2       0.82      0.90      0.86        51\n",
      "           3       0.96      0.92      0.94        51\n",
      "           4       0.87      0.94      0.91        51\n",
      "           5       0.98      1.00      0.99        51\n",
      "           6       0.93      0.78      0.85        51\n",
      "           7       0.82      0.92      0.87        51\n",
      "           8       0.90      0.87      0.88        52\n",
      "           9       1.00      0.84      0.91        51\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       511\n",
      "   macro avg       0.92      0.91      0.91       511\n",
      "weighted avg       0.92      0.91      0.91       511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 49,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  4, 46,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  3, 47,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 48,  0,  2,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 51,  0,  0,  0,  0],\n",
       "       [ 0,  0,  3,  0,  5,  0, 40,  3,  0,  0],\n",
       "       [ 0,  1,  0,  1,  0,  0,  0, 47,  2,  0],\n",
       "       [ 1,  0,  1,  1,  1,  0,  0,  3, 45,  0],\n",
       "       [ 0,  0,  1,  0,  1,  0,  0,  3,  3, 43]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        51\n",
      "           1       0.91      0.96      0.93        51\n",
      "           2       0.82      0.90      0.86        51\n",
      "           3       0.96      0.92      0.94        51\n",
      "           4       0.87      0.94      0.91        51\n",
      "           5       0.98      1.00      0.99        51\n",
      "           6       0.93      0.78      0.85        51\n",
      "           7       0.82      0.92      0.87        51\n",
      "           8       0.90      0.87      0.88        52\n",
      "           9       1.00      0.84      0.91        51\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       511\n",
      "   macro avg       0.92      0.91      0.91       511\n",
      "weighted avg       0.92      0.91      0.91       511\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[100.     0.     0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.    96.08   3.92   0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     7.84  90.2    0.     0.     0.     1.96   0.     0.     0.  ]\n",
      " [  0.     0.     5.88  92.16   0.     1.96   0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.    94.12   0.     3.92   1.96   0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.   100.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     5.88   0.     9.8    0.    78.43   5.88   0.     0.  ]\n",
      " [  0.     1.96   0.     1.96   0.     0.     0.    92.16   3.92   0.  ]\n",
      " [  1.92   0.     1.92   1.92   1.92   0.     0.     5.77  86.54   0.  ]\n",
      " [  0.     0.     1.96   0.     1.96   0.     0.     5.88   5.88  84.31]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19090c20d68>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion(true_classes, predicted_classes, \"MobileNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar modelo TensorflowJS (Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflowjs as tfjs\n",
    "#tfjs.converters.save_keras_model(model, tfjs_target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar modelo TensorflowLite (Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.contrib import lite\n",
    "\n",
    "#converter = lite.TocoConverter.from_keras_model_file(keras_model_file)\n",
    "#tflite_model = converter.convert()\n",
    "#open(\"resnet.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
