{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final\n",
    "Neste trabalho, vamos buscar o reconhecimento dos dígitos da Linguagem de Sinais. Para tal, vamos nos utilizar de Modelos conhecidos de Deep Learning e também nos aventurar na criação de próprios.\n",
    "\n",
    "------\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "import inf619utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "O dataset é composto por 10 classes (dígitos de 0 a 9) com aproximadamente 205 imagens por classe. \n",
    "O conjunto foi dividido em 60% para treinamento, 15% para validação e 20% para teste.\n",
    "As imagens estão divididas em blocos por classe.\n",
    "\n",
    "** IMPORTANTE NÃO ALTERAR O NOME/LOCAL DAS IMAGENS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDir = \"./Dataset\"\n",
    "nbClasses = 10\n",
    "input_shape = (100,100,3)\n",
    "\n",
    "train_files = {}\n",
    "val_files = {}\n",
    "test_files = {}\n",
    "\n",
    "train_files, val_files, test_files = inf619utils.splitData(datasetDir, nbClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the images from imgList\n",
    "def plotImagesFromBatch(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "\n",
    "\n",
    "# Se quiser visualizar algum bloco de imagens, descomentar as linhas abaixo\n",
    "# inf619utils.plotImages(val_files)\n",
    "# inf619utils.plotImages(train_files)\n",
    "# inf619utils.plotImages(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images in Train set:  1242\n",
      "# images in Val set:  309\n",
      "# images in Test set:  511\n"
     ]
    }
   ],
   "source": [
    "trainSetSize = inf619utils.getDatasetSize(train_files)\n",
    "valSetSize = inf619utils.getDatasetSize(val_files)\n",
    "testSetSize = inf619utils.getDatasetSize(test_files)\n",
    "\n",
    "print(\"# images in Train set: \", trainSetSize)\n",
    "print(\"# images in Val set: \", valSetSize)\n",
    "print(\"# images in Test set: \", testSetSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 100, 3) (32, 10)\n"
     ]
    }
   ],
   "source": [
    "for batch, labels in inf619utils.loadDatasetInBatches(train_files, batch_size=32, input_shape=input_shape, nbClasses=nbClasses):\n",
    "    print(batch.shape, labels.shape)\n",
    "    #plotImagesFromBatch(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modificação do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo base da squeezeNet \n",
    "squeezeNetModel = SqueezeNet((100,100,3))\n",
    "\n",
    "# Escolher a camada que será o ponto de partida \n",
    "x = squeezeNetModel.get_layer(name=\"fire9/concat\").output\n",
    "\n",
    "#print([layer.name for layer in squeezeNetModel.layers])\n",
    "#print(\"\\n\\nFreeze layers up until \", squeezeNetModel.layers[-20].name)\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    layer.trainable = True#        layer.trainable = False\n",
    "\n",
    "x = Convolution2D(1024, (1, 1), padding='valid', name='conv10_new')(x)\n",
    "x = Activation('relu', name='relu_conv10_new')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Convolution2D(nbClasses, (1, 1), padding='valid', name='conv11_new')(x)\n",
    "x = Activation('relu', name='relu_conv11_new')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='loss_new')(x)\n",
    "\n",
    "\n",
    "# Não se esqueça de definir o nome modelo, onde baseSqueezeNetModel \n",
    "# é o modelo base da Squeeze que vc definiu ali em cima\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "#Compile o modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True), metrics=['accuracy'])\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./logs_squeeze8\")\n",
    "tbEarly = callbacks.EarlyStopping(monitor='val_acc',min_delta=0,patience=10,verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 2.4067 - acc: 0.1184 - val_loss: 2.2337 - val_acc: 0.2674\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 2.2287 - acc: 0.2309 - val_loss: 2.1213 - val_acc: 0.3430\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 2.0932 - acc: 0.2832 - val_loss: 1.9419 - val_acc: 0.4477\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 1.8773 - acc: 0.3979 - val_loss: 1.6844 - val_acc: 0.4946\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 1.5637 - acc: 0.4891 - val_loss: 1.2680 - val_acc: 0.6462\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 12s 328ms/step - loss: 1.2160 - acc: 0.6153 - val_loss: 0.8881 - val_acc: 0.8014\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 0.8983 - acc: 0.7311 - val_loss: 0.6326 - val_acc: 0.8123\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 12s 316ms/step - loss: 0.6603 - acc: 0.7869 - val_loss: 0.5060 - val_acc: 0.8484\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 12s 320ms/step - loss: 0.5076 - acc: 0.8308 - val_loss: 0.3722 - val_acc: 0.9061\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 12s 317ms/step - loss: 0.3760 - acc: 0.8917 - val_loss: 0.2834 - val_acc: 0.9278\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 12s 314ms/step - loss: 0.3191 - acc: 0.9039 - val_loss: 0.2559 - val_acc: 0.9271\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 12s 305ms/step - loss: 0.2457 - acc: 0.9252 - val_loss: 0.1938 - val_acc: 0.9422\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 12s 305ms/step - loss: 0.2156 - acc: 0.9419 - val_loss: 0.2095 - val_acc: 0.9206\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 12s 305ms/step - loss: 0.1815 - acc: 0.9472 - val_loss: 0.1526 - val_acc: 0.9531\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.1775 - acc: 0.9507 - val_loss: 0.1593 - val_acc: 0.9422\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 0.1334 - acc: 0.9663 - val_loss: 0.1875 - val_acc: 0.9422\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.1413 - acc: 0.9622 - val_loss: 0.1260 - val_acc: 0.9711\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 11s 294ms/step - loss: 0.1098 - acc: 0.9735 - val_loss: 0.1143 - val_acc: 0.9711\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.1000 - acc: 0.9710 - val_loss: 0.1202 - val_acc: 0.9639\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.0833 - acc: 0.9825 - val_loss: 0.1236 - val_acc: 0.9675\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.0921 - acc: 0.9719 - val_loss: 0.1191 - val_acc: 0.9722\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 0.0716 - acc: 0.9825 - val_loss: 0.1190 - val_acc: 0.9675\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 0.0569 - acc: 0.9877 - val_loss: 0.1129 - val_acc: 0.9675\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.0695 - acc: 0.9860 - val_loss: 0.0615 - val_acc: 0.9747\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.0578 - acc: 0.9875 - val_loss: 0.1172 - val_acc: 0.9747\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 0.0688 - acc: 0.9852 - val_loss: 0.1165 - val_acc: 0.9603\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 0.0498 - acc: 0.9885 - val_loss: 0.1202 - val_acc: 0.9747\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.0474 - acc: 0.9885 - val_loss: 0.0737 - val_acc: 0.9747\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 12s 314ms/step - loss: 0.0386 - acc: 0.9942 - val_loss: 0.1013 - val_acc: 0.9783\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 11s 293ms/step - loss: 0.0416 - acc: 0.9918 - val_loss: 0.1010 - val_acc: 0.9783\n"
     ]
    }
   ],
   "source": [
    "#Definir tamanho do batch e número de épocas\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "#Criação dos generators\n",
    "trainGenerator = inf619utils.loadDatasetInBatches(train_files, batch_size = batch_size, input_shape=input_shape, nbClasses=nbClasses)\n",
    "valGenerator = inf619utils.loadDatasetInBatches(val_files, batch_size = batch_size)\n",
    "\n",
    "#Fit nos dados\n",
    "hist = model.fit_generator(trainGenerator, \n",
    "                    steps_per_epoch= int(trainSetSize / batch_size), \n",
    "                    epochs = epochs,\n",
    "                    validation_data = valGenerator,  \n",
    "                    validation_steps = int(valSetSize / batch_size),\n",
    "                    callbacks=[tbCallBack, tbEarly])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do Modelo no Conjunto de Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 114ms/step\n",
      "Test Loss --->  0.09766870339711507\n",
      "Test Accuracy --->  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "#Criação do generator p/ o conjunto de teste\n",
    "testGenerator = inf619utils.loadDatasetInBatches(test_files, batch_size=batch_size)\n",
    "\n",
    "#Teste\n",
    "metrics = model.evaluate_generator(testGenerator, \n",
    "                                   steps=int(testSetSize/batch_size), \n",
    "                                   verbose=1)\n",
    "\n",
    "print(\"Test Loss ---> \", metrics[0])\n",
    "print(\"Test Accuracy ---> \", metrics[1])    #Test is balanced, so Acc is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
